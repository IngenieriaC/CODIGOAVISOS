
# --- Initialize session state ---
if 'df' not in st.session_state:
    st.session_state.df = None
if 'evaluations' not in st.session_state:
    st.session_state.evaluations = {}
if 'selected_eval_target' not in st.session_state:
    st.session_state.selected_eval_target = None
if 'eval_mode' not in st.session_state:
    st.session_state.eval_mode = "Por Tipo de Servicio" # Default mode
if 'pre_calculated_metrics' not in st.session_state:
    st.session_state.pre_calculated_metrics = {}
if 'original_excel_buffer' not in st.session_state:
    st.session_state.original_excel_buffer = None
if 'page' not in st.session_state:
    st.session_state.page = "Inicio y Carga de Datos"


# Dummy horarios_dict for demonstration purposes if not provided in original code
# You should replace this with your actual horarios_dict
horarios_dict = {
    'equipo_a': (8, 365),
    'equipo_b': (16, 300),
    'equipo_c': (24, 365),
}

# --- Funciones para cargar y preprocesar datos ---
def load_and_merge_data(uploaded_file):
    xls = pd.ExcelFile(uploaded_file)
    df_avisos = pd.read_excel(xls, sheet_name='Hoja1') # Assuming 'Hoja1' for main data
    
    # Normalize column names by replacing spaces and special characters, converting to lowercase
    df_avisos.columns = [
        col.lower().replace(' ', '_').replace('.', '').replace('(', '').replace(')', '').replace('√≥', 'o').replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√∫', 'u')
        for col in df_avisos.columns
    ]

    # Ensure 'costes_tot_reales' and 'duracion_de_parada' are numeric
    if 'costes_tot_reales' in df_avisos.columns:
        df_avisos['costes_tot_reales'] = pd.to_numeric(df_avisos['costes_tot_reales'], errors='coerce').fillna(0)
    else:
        st.warning("La columna 'costes_tot_reales' no se encontr√≥. Los an√°lisis de costos no estar√°n disponibles.")
        df_avisos['costes_tot_reales'] = 0 # Add dummy column to avoid errors

    if 'duracion_de_parada' in df_avisos.columns:
        df_avisos['duracion_de_parada'] = pd.to_numeric(df_avisos['duracion_de_parada'], errors='coerce').fillna(0)
    else:
        st.warning("La columna 'duracion_de_parada' no se encontr√≥. Los c√°lculos de MTTR, MTBF y Disponibilidad pueden ser incorrectos.")
        df_avisos['duracion_de_parada'] = 0 # Add dummy column

    # Rename 'denominacion_ejecutante' to 'proveedor' if it exists
    if 'denominacion_ejecutante' in df_avisos.columns:
        df_avisos.rename(columns={'denominacion_ejecutante': 'proveedor'}, inplace=True)
    elif 'proveedor' not in df_avisos.columns:
        df_avisos['proveedor'] = 'Desconocido' # Fallback if neither exists

    # Ensure 'tipo_de_servicio' exists for technical metrics
    if 'tipo_de_servicio' not in df_avisos.columns:
        df_avisos['tipo_de_servicio'] = 'Sin Servicio' # Fallback

    # Ensure 'status_del_sistema' exists for filtering
    if 'status_del_sistema' not in df_avisos.columns:
        df_avisos['status_del_sistema'] = '' # Fallback for filtering

    # Ensure 'aviso' exists for counting
    if 'aviso' not in df_avisos.columns:
        df_avisos['aviso'] = np.arange(len(df_avisos)) # Create dummy unique IDs

    # Ensure 'denominacion_de_objeto_tecnico' exists for technical metrics
    if 'denominacion_de_objeto_tecnico' not in df_avisos.columns:
        df_avisos['denominacion_de_objeto_tecnico'] = 'Desconocido' # Fallback

    # Ensure 'equipo' exists for technical metrics
    if 'equipo' not in df_avisos.columns:
        df_avisos['equipo'] = df_avisos['denominacion_de_objeto_tecnico'] # Use object name if equipment not present

    return df_avisos


# --- Funciones para calcular indicadores de desempe√±o t√©cnico ---
def calcular_disponibilidad(df_subset: pd.DataFrame, horarios: dict) -> pd.Series:
    """Calcula la disponibilidad promedio por Tipo de Servicio, promediando la disponibilidad de los equipos."""
    if df_subset.empty:
        return pd.Series(dtype=float)

    # Ensure 'duracion_de_parada' is numeric
    df_subset['duracion_de_parada'] = pd.to_numeric(df_subset['duracion_de_parada'], errors='coerce').fillna(0)

    # Calculate operational hours per equipment based on 'denominacion_de_objeto_tecnico'
    # Use 'equipo' directly if available, otherwise 'denominacion_de_objeto_tecnico'
    if 'denominacion_de_objeto_tecnico' not in df_subset.columns:
        df_subset['denominacion_de_objeto_tecnico'] = 'Desconocido'

    # Map equipment to a horario key based on substring match in 'denominacion_de_objeto_tecnico'
    df_subset['Horario_Key'] = df_subset['denominacion_de_objeto_tecnico'].apply(
        lambda x: next((key for key in horarios.keys() if key.lower() in str(x).lower()), None)
    )

    # Handle cases where no specific horario key is found
    default_horas_dia = np.mean([h[0] for h in horarios.values()]) if horarios else 8 # Default to 8 if no horarios
    default_dias_anio = np.mean([h[1] for h in horarios.values()]) if horarios else 365 # Default to 365 if no horarios

    df_subset['Horas_Dia_Equipo'] = df_subset.apply(
        lambda row: horarios[row['Horario_Key']][0] if row['Horario_Key'] in horarios else default_horas_dia,
        axis=1
    )
    df_subset['Dias_Anio_Equipo'] = df_subset.apply(
        lambda row: horarios[row['Horario_Key']][1] if row['Horario_Key'] in horarios else default_dias_anio,
        axis=1
    )

    df_subset['Horas_Operativas_Totales'] = df_subset['Horas_Dia_Equipo'] * df_subset['Dias_Anio_Equipo']

    # Group by 'equipo' to calculate sum of downtime and total operational hours
    # Use 'equipo' if it exists, otherwise use 'denominacion_de_objeto_tecnico'
    group_by_col_eq = 'equipo' if 'equipo' in df_subset.columns else 'denominacion_de_objeto_tecnico'

    sum_parada_equipo = df_subset.groupby(group_by_col_eq)['duracion_de_parada'].sum()
    horas_op_equipo = df_subset.drop_duplicates(subset=group_by_col_eq).set_index(group_by_col_eq)['Horas_Operativas_Totales']

    # Reindex to ensure alignment and fill missing values
    horas_op_equipo = horas_op_equipo.reindex(sum_parada_equipo.index).fillna(0)

    # Calculate availability per equipment
    # Handle division by zero for total operational hours
    disponibilidad_equipo = (horas_op_equipo - sum_parada_equipo) / horas_op_equipo * 100
    disponibilidad_equipo = disponibilidad_equipo.replace([-np.inf, np.inf], np.nan).fillna(0) # Replace inf with 0% availability

    # Now, aggregate availability by 'tipo_de_servicio' or 'proveedor'
    # This assumes that 'equipo' is linked to 'tipo_de_servicio' or 'proveedor' in the original df_subset
    if 'tipo_de_servicio' in df_subset.columns and not df_subset['tipo_de_servicio'].isnull().all():
        disponibilidad_by_eval_target = df_subset.groupby('tipo_de_servicio')[group_by_col_eq].apply(
            lambda equipos: disponibilidad_equipo[equipos.unique()].mean() if not equipos.empty and not disponibilidad_equipo[equipos.unique()].empty else 0
        )
    elif 'proveedor' in df_subset.columns and not df_subset['proveedor'].isnull().all():
        disponibilidad_by_eval_target = df_subset.groupby('proveedor')[group_by_col_eq].apply(
            lambda equipos: disponibilidad_equipo[equipos.unique()].mean() if not equipos.empty and not disponibilidad_equipo[equipos.unique()].empty else 0
        )
    else:
        st.warning("No 'tipo_de_servicio' or 'proveedor' column found for availability aggregation. Returning overall mean.")
        disponibilidad_by_eval_target = pd.Series([disponibilidad_equipo.mean()], index=['General'])

    return disponibilidad_by_eval_target


def calcular_mttr(df_subset: pd.DataFrame) -> pd.Series:
    """Calcula el MTTR promedio por Tipo de Servicio o Proveedor."""
    if df_subset.empty:
        return pd.Series(dtype=float)
    df_subset['duracion_de_parada'] = pd.to_numeric(df_subset['duracion_de_parada'], errors='coerce').fillna(0)

    if 'tipo_de_servicio' in df_subset.columns and not df_subset['tipo_de_servicio'].isnull().all():
        group_by_col = 'tipo_de_servicio'
    elif 'proveedor' in df_subset.columns and not df_subset['proveedor'].isnull().all():
        group_by_col = 'proveedor'
    else:
        st.warning("No 'tipo_de_servicio' or 'proveedor' column found for MTTR calculation. Returning overall mean.")
        return pd.Series([df_subset['duracion_de_parada'].sum() / df_subset['aviso'].nunique() if df_subset['aviso'].nunique() > 0 else 0], index=['General'])

    mttr = df_subset.groupby(group_by_col).apply(
        lambda x: x['duracion_de_parada'].sum() / x['aviso'].nunique() if x['aviso'].nunique() > 0 else 0
    )
    return mttr.replace([np.inf, -np.inf], np.nan).fillna(0)

def calcular_mtbf(df_subset: pd.DataFrame, horarios: dict) -> pd.Series:
    """Calcula el MTBF promedio por Tipo de Servicio o Proveedor."""
    if df_subset.empty:
        return pd.Series(dtype=float)

    df_subset['duracion_de_parada'] = pd.to_numeric(df_subset['duracion_de_parada'], errors='coerce').fillna(0)

    if 'denominacion_de_objeto_tecnico' not in df_subset.columns:
        df_subset['denominacion_de_objeto_tecnico'] = 'Desconocido'

    df_subset['Horario_Key'] = df_subset['denominacion_de_objeto_tecnico'].apply(
        lambda x: next((key for key in horarios.keys() if key.lower() in str(x).lower()), None)
    )
    default_horas_dia = np.mean([h[0] for h in horarios.values()]) if horarios else 8
    default_dias_anio = np.mean([h[1] for h in horarios.values()]) if horarios else 365

    df_subset['Horas_Dia_Equipo'] = df_subset.apply(
        lambda row: horarios[row['Horario_Key']][0] if row['Horario_Key'] in horarios else default_horas_dia,
        axis=1
    )
    df_subset['Dias_Anio_Equipo'] = df_subset.apply(
        lambda row: horarios[row['Horario_Key']][1] if row['Horario_Key'] in horarios else default_dias_anio,
        axis=1
    )
    df_subset['Horas_Operativas_Totales_Equipo'] = df_subset['Horas_Dia_Equipo'] * df_subset['Dias_Anio_Equipo']

    group_by_col_eq = 'equipo' if 'equipo' in df_subset.columns else 'denominacion_de_objeto_tecnico'

    total_parada_por_equipo = df_subset.groupby(group_by_col_eq)['duracion_de_parada'].sum()
    num_avisos_por_equipo = df_subset.groupby(group_by_col_eq)['aviso'].nunique()

    horas_op_unicas_equipo = df_subset.drop_duplicates(subset=group_by_col_eq).set_index(group_by_col_eq)['Horas_Operativas_Totales_Equipo']

    total_parada_por_equipo = total_parada_por_equipo.reindex(horas_op_unicas_equipo.index).fillna(0)
    num_avisos_por_equipo = num_avisos_por_equipo.reindex(horas_op_unicas_equipo.index).fillna(0)

    # Avoid division by zero: if num_avisos_por_equipo is 0, MTBF is considered infinite or 0 depending on context. Here, 0.
    mtbf_equipo = (horas_op_unicas_equipo - total_parada_por_equipo) / num_avisos_por_equipo
    mtbf_equipo = mtbf_equipo.replace([np.inf, -np.inf], np.nan).fillna(0) # Manejar divisiones por cero

    if 'tipo_de_servicio' in df_subset.columns and not df_subset['tipo_de_servicio'].isnull().all():
        group_by_col_eval = 'tipo_de_servicio'
    elif 'proveedor' in df_subset.columns and not df_subset['proveedor'].isnull().all():
        group_by_col_eval = 'proveedor'
    else:
        st.warning("No 'tipo_de_servicio' or 'proveedor' column found for MTBF aggregation. Returning overall mean.")
        return pd.Series([mtbf_equipo.mean()], index=['General'])

    mtbf_by_eval_target = df_subset.groupby(group_by_col_eval)[group_by_col_eq].apply(
        lambda equipos: mtbf_equipo[equipos.unique()].mean() if not equipos.empty and not mtbf_equipo[equipos.unique()].empty else 0
    )
    return mtbf_by_eval_target

def clasificar_rendimiento(disponibilidad: pd.Series) -> pd.Series:
    """Clasifica el rendimiento en 'Alto', 'Medio' o 'Bajo' basado en la disponibilidad."""
    if disponibilidad.empty:
        return pd.Series(dtype=str)

    return disponibilidad.apply(
        lambda disp: 'Alto' if disp >= 90 else ('Medio' if disp >= 75 else 'Bajo')
    )

# --- Definici√≥n de las preguntas y rangos ---
rangos_detallados = {
    "Calidad": {
        "¬øLas soluciones propuestas son coherentes con el diagn√≥stico y causa ra√≠z del problema?": {
            2: "Total coherencia con el diagn√≥stico y causas identificadas",
            1: "Coherencia razonable, con peque√±os ajustes necesarios",
            0: "Cumple con lo b√°sico, pero con limitaciones relevantes",
            -1: "No guarda coherencia o es deficiente respecto al diagn√≥stico"
        },
        "¬øEl trabajo entregado tiene materiales nuevos, originales y de marcas reconocidas?": {
            2: "Todos los materiales son nuevos, originales y de marcas reconocidas",
            1: "La mayor√≠a de los materiales cumplen esas condiciones",
            0: "Algunos materiales no son nuevos o no est√°n certificados",
            -1: "Materiales gen√©ricos, usados o sin respaldo de marca"
        },
        "¬øCuenta con acabados homog√©neos, limpios y pulidos?": {
            2: "Acabados uniformes, bien presentados y profesionales",
            1: "En general, los acabados son aceptables y limpios",
            0: "Presenta inconsistencias notorias en algunos acabados",
            -1: "Acabados descuidados, sucios o sin terminaci√≥n adecuada"
        },
        "¬øEl trabajo entregado corresponde completamente con lo contratado?": {
            2: "Cumple en su totalidad con lo contratado y acordado",
            1: "Cumple en gran parte con lo contratado, con m√≠nimos desv√≠os",
            0: "Cumple con los requisitos m√≠nimos establecidos",
            -1: "No corresponde con lo contratado o presenta deficiencias importantes"
        },
        "¬øLa facturaci√≥n refleja correctamente lo ejecutado y acordado?": {
            2: "Facturaci√≥n precisa, sin errores y con toda la informaci√≥n requerida",
            1: "Facturaci√≥n con peque√±os errores que no afectan el control",
            0: "Facturaci√≥n con errores importantes (por ejemplo, precios)",
            -1: "Facturaci√≥n incorrecta, incompleta o que requiere ser repetida"
        }
    },
    "Oportunidad": {
        "¬øLa entrega de cotizaciones fue oportuna, seg√∫n el contrato?": {
            2: "Siempre entrega cotizaciones en los tiempos establecidos",
            1: "Generalmente cumple con los plazos establecidos",
            0: "A veces entrega fuera del tiempo estipulado",
            -1: "Frecuentemente incumple los tiempos o no entrega"
        },
        "¬øEl reporte del servicio fue entregado oportunamente, seg√∫n el contrato?": {
            2: "Siempre entrega los reportes a tiempo, seg√∫n lo acordado",
            1: "Entrega los reportes con m√≠nimos retrasos",
            0: "Entrega con demoras ocasionales",
            -1: "Entrega tard√≠a constante o no entrega"
        },
        "¬øCumple las fechas y horas programadas para los trabajos, seg√∫n el contrato?": {
            2: "Puntualidad absoluta en fechas y horarios de ejecuci√≥n",
            1: "Puntualidad general con excepciones menores",
            0: "Cumplimiento parcial o con retrasos frecuentes",
            -1: "Incumplimiento reiterado de horarios o fechas"
        },
        "¬øResponde de forma efectiva ante eventualidades emergentes, seg√∫n el contrato?": {
            2: "Respuesta inmediata y eficaz ante cualquier eventualidad",
            1: "Respuesta adecuada en la mayor√≠a de los casos",
            0: "Respuesta tard√≠a o poco efectiva en varias situaciones",
            -1: "No responde adecuadamente o ignora emergencias"
        },
        "¬øSoluciona r√°pidamente reclamos o inquietudes por garant√≠a, seg√∫n el contrato?": {
            2: "Soluciona siempre con rapidez y eficacia",
            1: "Responde satisfactoriamente en la mayor√≠a de los casos",
            0: "Respuesta variable, con demoras ocasionales",
            -1: "Soluciones lentas o sin resolver adecuadamente"
        },
        "¬øDispone de los repuestos requeridos en los tiempos necesarios, seg√∫n el contrato?": {
            2: "Siempre cuenta con repuestos disponibles en el tiempo requerido",
            1: "Generalmente cumple con la disponibilidad de repuestos",
            0: "Disponibilidad intermitente o con retrasos",
            -1: "No garantiza disponibilidad o presenta retrasos constantes"
        },
        "¬øEntrega las facturas en los tiempos convenidos, seg√∫n el contrato?": {
            2: "Entrega siempre puntual de facturas",
            1: "Entrega generalmente puntual con pocas excepciones",
            0: "Entrega ocasionalmente fuera del tiempo acordado",
            -1: "Entrega tarde con frecuencia o no entrega"
        }
    },
    "Precio": {
        "¬øLos precios ofrecidos para equipos son competitivos respecto al mercado?": {
            2: "Muy por debajo del precio promedio de mercado",
            1: "Por debajo del promedio de mercado",
            0: "Igual al promedio de mercado",
            -1: "Por encima del promedio de mercado"
        },
        "¬øLos precios ofrecidos para repuestos son competitivos respecto al mercado?": {
            2: "Muy por debajo del precio promedio de mercado",
            1: "Por debajo del promedio de mercado",
            0: "Igual al promedio de mercado",
            -1: "Por encima del promedio de mercado"
        },
        "Facilita llegar a una negociaci√≥n (precios)": {
            2: "Siempre est√° dispuesto a negociar de manera flexible",
            1: "En general muestra disposici√≥n al di√°logo",
            0: "Ocasionalmente permite negociar",
            -1: "Poco o nada dispuesto a negociar"
        },
        "Pone en consideraci√≥n contratos y trabajos adjudicados en el √∫ltimo periodo de tiempo": {
            2: "Siempre toma en cuenta la relaci√≥n comercial previa",
            1: "Generalmente considera trabajos anteriores",
            0: "Solo ocasionalmente lo toma en cuenta",
            -1: "No muestra continuidad ni reconocimiento de antecedentes"
        },
        "¬øLos precios ofrecidos para mantenimientos son competitivos respecto al mercado?": {
            2: "Muy por debajo del precio promedio de mercado",
            1: "Por debajo del promedio de mercado",
            0: "Igual al promedio de mercado",
            -1: "Por encima del promedio de mercado"
        },
        "¬øLos precios ofrecidos para insumos son competitivos respecto al mercado?": {
            2: "Muy por debajo del precio promedio de mercado",
            1: "Por debajo del promedio de mercado",
            0: "Igual al promedio de mercado",
            -1: "Por encima del promedio de mercado"
        }
    },
    "Postventa": {
        "¬øTiene disposici√≥n y actitud de servicio frente a solicitudes?": {
            2: "Atenci√≥n proactiva y excelente actitud de servicio",
            1: "Buena actitud y disposici√≥n general",
            0: "Actitud pasiva o limitada ante las solicitudes",
            -1: "Falta de disposici√≥n o actitudes negativas"
        },
        "¬øConoce necesidades y ofrece alternativas adecuadas?": {
            2: "Conocimiento profundo del cliente y propuestas adecuadas",
            1: "Buen conocimiento y alternativas en general adecuadas",
            0: "Soluciones parcialmente adecuadas",
            -1: "No se adapta a las necesidades o propone soluciones inadecuadas"
        },
        "¬øRealiza seguimiento a los resultados de los trabajos?": {
            2: "Hace seguimiento sistem√°tico y detallado",
            1: "Realiza seguimiento general adecuado",
            0: "Seguimiento ocasional o no documentado",
            -1: "No realiza seguimiento posterior"
        },
        "¬øOfrece capacitaciones para el manejo de los equipos?": {
            2: "Capacitaciones constantes y bien estructuradas",
            1: "Capacitaciones ocasionales pero √∫tiles",
            0: "Capacitaciones m√≠nimas o informales",
            -1: "No ofrece capacitaciones"
        },
        "¬øLos m√©todos de capacitaci√≥n ofrecidos son efectivos y adecuados?": {
            2: "M√©todos claros, efectivos y adaptados al usuario",
            1: "M√©todos generalmente √∫tiles y comprensibles",
            0: "M√©todos poco claros o limitados",
            -1: "M√©todos ineficaces o mal estructurados"
        }
    },
    "Desempe√±o t√©cnico": {
        "Disponibilidad promedio (%)": {
            2: "Disponibilidad >= 98%",
            1: "75% <= Disponibilidad < 98%",
            0: "Disponibilidad < 75%"
        },
        "MTTR promedio (hrs)": {
            2: "MTTR <= 5 hrs",
            1: "5 hrs < MTTR <= 20 hrs",
            0: "MTTR > 20 hrs"
        },
        "MTBF promedio (hrs)": {
            2: "MTBF > 1000 hrs",
            1: "100 hrs <= MTBF <= 1000 hrs",
            0: "MTBF < 100 hrs"
        },
        "Rendimiento promedio equipos": {
            2: "Rendimiento 'Alto' (Disponibilidad >= 90%)",
            1: "Rendimiento 'Medio' (75% <= Disponibilidad < 90%)",
            0: "Rendimiento 'Bajo' (Disponibilidad < 75%)"
        }
    }
}

# --- Clase para el manejo de an√°lisis generalizado y paginaci√≥n ---
class AnalysisApp:
    def __init__(self, df):
        self.df = df
        # Usar nombres de columnas normalizados
        self.EJECUTANTE_COL_NAME_NORMALIZED = "proveedor"
        # CORRECTED: Use 'costes_tot_reales' as the normalized cost column name
        self.COL_COSTOS_NORMALIZED = "costes_tot_reales" 
        self.COL_DURACION_PARADA_NORMALIZED = "duracion_de_parada"

        # Categorizaci√≥n de descripci√≥n (ejemplo, puedes refinar esta l√≥gica)
        if 'descripcion' in self.df.columns:
            self.df['description_category'] = self.df['descripcion'].apply(self._categorize_description)
        else:
            self.df['description_category'] = "Sin Categor√≠a" # Fallback

        # Opciones de an√°lisis din√°micas
        self.opciones_menu = {
            "Costos por Ejecutante": (self.EJECUTANTE_COL_NAME_NORMALIZED, self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Ejecutante": (self.EJECUTANTE_COL_NAME_NORMALIZED, None, "avisos"), # None para conteo de avisos
            "Costos por Objeto T√©cnico": ("denominacion_de_objeto_tecnico", self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Objeto T√©cnico": ("denominacion_de_objeto_tecnico", None, "avisos"),
            "Costos por Texto C√≥digo Acci√≥n": ("texto_codigo_accion", self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Texto C√≥digo Acci√≥n": ("texto_codigo_accion", None, "avisos"),
            "Costos por Texto de Acci√≥n": ("texto_de_accion", self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Texto de Acci√≥n": ("texto_de_accion", None, "avisos"),
            "Costos por Tipo de Servicio": ("tipo_de_servicio", self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Tipo de Servicio": ("tipo_de_servicio", None, "avisos"),
            "Costos por Categor√≠a de Descripci√≥n": ("description_category", self.COL_COSTOS_NORMALIZED, "costos"),
            "Avisos por Categor√≠a de Descripci√≥n": ("description_category", None, "avisos"),
        }
        
        # Filter options to ensure columns exist in the DataFrame
        # CRITICAL FIX: Ensure 'costes_tot_reales' is in self.df.columns for cost options to appear.
        self.opciones_menu = {
            k: v for k, v in self.opciones_menu.items()
            if (v[0] in self.df.columns or v[0] == "description_category") 
            and (v[1] is None or (v[1] in self.df.columns and not self.df[v[1]].isnull().all())) # Check if cost column exists AND is not all null
        }
        
        if not self.opciones_menu:
            st.warning("No hay opciones de an√°lisis disponibles. Verifica que las columnas necesarias existan y tengan datos.")


    def _categorize_description(self, description):
        """Categoriza las descripciones (ejemplo, expande seg√∫n tus necesidades)."""
        desc = str(description).lower()
        if "reparacion" in desc or "mantenimiento correctivo" in desc:
            return "Reparaci√≥n/Mantenimiento Correctivo"
        elif "preventivo" in desc or "revision" in desc:
            return "Mantenimiento Preventivo/Revisi√≥n"
        elif "instalacion" in desc:
            return "Instalaci√≥n"
        else:
            return "Otros"

    def display_analysis(self):
        st.subheader("An√°lisis General de Datos")

        analysis_type = st.selectbox(
            "Selecciona el tipo de an√°lisis:",
            list(self.opciones_menu.keys()),
            key="analysis_type_select"
        )

        group_col, value_col, analysis_metric = self.opciones_menu[analysis_type]

        # Asegurarse que la columna de agrupaci√≥n exista (excepto para 'description_category' que es nueva)
        if group_col not in self.df.columns and group_col != "description_category":
            st.warning(f"La columna '{group_col}' no se encontr√≥ en los datos para este an√°lisis.")
            return

        if analysis_metric == "costos":
            if value_col not in self.df.columns:
                st.warning(f"La columna de costos '{value_col}' no se encontr√≥ en los datos para este an√°lisis.")
                return
            grouped_data = self.df.groupby(group_col)[value_col].sum().sort_values(ascending=False)
            title = f"Costos Totales por {analysis_type.split(' por ')[1].replace('por', 'seg√∫n')}"
            y_label = "Costo Total Real"
        elif analysis_metric == "avisos":
            grouped_data = self.df.groupby(group_col)['aviso'].nunique().sort_values(ascending=False)
            title = f"Cantidad de Avisos por {analysis_type.split(' por ')[1].replace('por', 'seg√∫n')}"
            y_label = "Cantidad de Avisos"
        else:
            st.error("M√©trica de an√°lisis no reconocida.")
            return

        # Paginaci√≥n
        items_per_page = 15
        total_items = len(grouped_data)
        total_pages = (total_items + items_per_page - 1) // items_per_page

        # Inicializa la p√°gina actual si no existe o si se cambia el tipo de an√°lisis
        if f'analysis_page_{analysis_type}' not in st.session_state:
            st.session_state[f'analysis_page_{analysis_type}'] = 0
            
        current_page = st.session_state[f'analysis_page_{analysis_type}']

        start_idx = current_page * items_per_page
        end_idx = min(start_idx + items_per_page, total_items)
        
        paginated_data = grouped_data.iloc[start_idx:end_idx]

        st.write(f"### {title}")
        st.dataframe(paginated_data.reset_index().rename(columns={grouped_data.name: y_label}))

        # Controles de paginaci√≥n
        col1, col2, col3 = st.columns([1, 2, 1])
        with col1:
            if st.button("P√°gina Anterior", key=f"prev_page_{analysis_type}"):
                if current_page > 0:
                    st.session_state[f'analysis_page_{analysis_type}'] -= 1
                    st.rerun()
        with col2:
            st.write(f"P√°gina {current_page + 1} de {total_pages}")
        with col3:
            if st.button("P√°gina Siguiente", key=f"next_page_{analysis_type}"):
                if current_page < total_pages - 1:
                    st.session_state[f'analysis_page_{analysis_type}'] += 1
                    st.rerun()

        # Gr√°fico
        if not paginated_data.empty:
            fig, ax = plt.subplots(figsize=(10, max(6, len(paginated_data) * 0.5)))
            sns.barplot(x=paginated_data.values, y=paginated_data.index, ax=ax, palette='viridis')
            ax.set_title(title)
            ax.set_xlabel(y_label)
            ax.set_ylabel(group_col)
            plt.tight_layout()
            st.pyplot(fig)
        else:
            st.info("No hay datos para mostrar en esta p√°gina.")


# --- Sidebar para navegaci√≥n ---
st.sidebar.title("Men√∫ Principal")
page_options = [
    "Inicio y Carga de Datos",
    "Evaluaci√≥n de Desempe√±o",
    "An√°lisis General", # Cambiado a "An√°lisis General"
]
selected_page = st.sidebar.radio("Ir a:", page_options, key="main_menu_selection")
st.session_state.page = selected_page

# --- Contenido de la p√°gina ---

if st.session_state.page == "Inicio y Carga de Datos":
    st.title("¬°Hola, usuario Sura! üëã")
    st.markdown("---")
    st.header("Proyecto de **Gerencia de Gesti√≥n Administrativa** en Ingenier√≠a Cl√≠nica")
    st.markdown("""
        Aqu√≠ podr√°s **analizar y gestionar los datos de avisos** para optimizar los procesos.
        Por favor, **sube el archivo `BASE DE DATOS.XLSX`** para comenzar.
    """)

    uploaded_file = st.file_uploader("Sube tu archivo 'BASE DE DATOS.XLSX' aqu√≠", type=["xlsx"])

    if uploaded_file:
        # Guardar el buffer del archivo original para descarga
        st.session_state.original_excel_buffer = io.BytesIO(uploaded_file.getvalue())
        st.session_state.original_excel_buffer.seek(0) # Rebobinar para futuras lecturas

        file_buffer = io.BytesIO(uploaded_file.getvalue())

        with st.spinner('Cargando y procesando datos... Esto puede tomar un momento.'):
            try:
                df_processed = load_and_merge_data(file_buffer)

                initial_rows = len(df_processed)
                # Aseg√∫rate de usar el nombre de columna normalizado 'status_del_sistema'
                if 'status_del_sistema' in df_processed.columns:
                    df_processed = df_processed[~df_processed["status_del_sistema"].str.contains("PTBO", case=False, na=False)]
                    st.info(f"Se eliminaron {initial_rows - len(df_processed)} registros con 'PTBO' en 'Status del sistema'.")
                
                st.session_state.df = df_processed

                # Pre-calculate all technical metrics once after data load
                st.session_state.pre_calculated_metrics = {}
                
                # The metric functions now receive the normalized DataFrame,
                # they internally decide whether to group by 'tipo_de_servicio' or 'proveedor'
                # based on which column is available and non-null.
                st.session_state.pre_calculated_metrics['disponibilidad'] = calcular_disponibilidad(st.session_state.df, horarios_dict)
                st.session_state.pre_calculated_metrics['mttr'] = calcular_mttr(st.session_state.df)
                st.session_state.pre_calculated_metrics['mtbf'] = calcular_mtbf(st.session_state.df, horarios_dict)
                # For rendimiento, we need the specific availability series returned by calcular_disponibilidad
                st.session_state.pre_calculated_metrics['rendimiento'] = clasificar_rendimiento(st.session_state.pre_calculated_metrics['disponibilidad'])
                
                st.success("‚úÖ Datos cargados y procesados exitosamente.")
                st.write(f"**Filas finales:** {len(st.session_state.df)} ‚Äì **Columnas:** {len(st.session_state.df.columns)}")

                st.markdown("---")
                st.subheader("Descarga de Datos")

                # Bot√≥n para descargar el archivo Excel original
                if st.session_state.original_excel_buffer:
                    st.download_button(
                        label="Descargar Excel Original",
                        data=st.session_state.original_excel_buffer,
                        file_name="BASE_DE_DATOS_original.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="download_original_excel"
                    )

                csv_output = st.session_state.df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="Descargar Datos Procesados (CSV)",
                    data=csv_output,
                    file_name="avisos_filtrados.csv",
                    mime="text/csv",
                    help="Descarga el archivo procesado en formato CSV."
                )

                excel_buffer_processed = io.BytesIO()
                st.session_state.df.to_excel(excel_buffer_processed, index=False, engine='openpyxl')
                excel_buffer_processed.seek(0)
                st.download_button(
                    label="Descargar Datos Procesados (Excel)",
                    data=excel_buffer_processed,
                    file_name="avisos_filtrados.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    help="Descarga el archivo procesado en formato XLSX."
                )

                st.markdown("---")
                st.success("¬°El procesamiento ha finalizado! Ahora puedes descargar tus datos o seguir explorando otras secciones.")

            except Exception as e:
                st.error(f"‚ùå ¬°Ups! Ocurri√≥ un error al procesar el archivo: {e}")
                st.warning("Por favor, verifica que el archivo subido sea `BASE DE DATOS.XLSX` y tenga el formato de hojas esperado.")
                st.exception(e)
    else:
        st.info("‚¨ÜÔ∏è Sube tu archivo `BASE DE DATOS.XLSX` para empezar con el an√°lisis.")

# --- Secci√≥n de Evaluaci√≥n de Desempe√±o ---
elif st.session_state.page == "Evaluaci√≥n de Desempe√±o":
    st.title("üìä Evaluaci√≥n de Desempe√±o")
    st.markdown("""
        Utiliza esta secci√≥n para evaluar el desempe√±o de los **proveedores** o **tipos de servicio**
        basado en criterios de calidad, oportunidad, precio y postventa, adem√°s de visualizar m√©tricas de desempe√±o t√©cnico.
    """)

    if st.session_state.df is None or st.session_state.df.empty:
        st.warning("Por favor, carga el archivo `BASE DE DATOS.XLSX` en la secci√≥n 'Inicio y Carga de Datos' para acceder a la evaluaci√≥n.")
    else:
        # Selecci√≥n del modo de evaluaci√≥n
        st.session_state.eval_mode = st.radio(
            "Selecciona el modo de evaluaci√≥n:",
            ("Por Tipo de Servicio", "Por Proveedor"),
            index=0 if st.session_state.eval_mode == "Por Tipo de Servicio" else 1,
            key="eval_mode_radio"
        )

        target_column_name_internal = ''
        if st.session_state.eval_mode == "Por Tipo de Servicio":
            if 'tipo_de_servicio' in st.session_state.df.columns and not st.session_state.df['tipo_de_servicio'].isnull().all():
                eval_targets = sorted(st.session_state.df['tipo_de_servicio'].dropna().unique().tolist())
                target_column_name_internal = 'tipo_de_servicio'
            else:
                eval_targets = []
                st.warning("No hay 'Tipo de Servicio' v√°lidos para evaluar. Aseg√∫rate de que la columna exista y no est√© vac√≠a.")
        else: # Por Proveedor
            if 'proveedor' in st.session_state.df.columns and not st.session_state.df['proveedor'].isnull().all():
                eval_targets = sorted(st.session_state.df['proveedor'].dropna().unique().tolist())
                target_column_name_internal = 'proveedor'
            else:
                eval_targets = []
                st.warning("No hay 'Proveedor' v√°lidos para evaluar. Aseg√∫rate de que la columna exista y no est√© vac√≠a.")

        if not eval_targets:
            st.info("No hay objetivos de evaluaci√≥n disponibles. Sube un archivo con datos v√°lidos.")
        else:
            # Initialize selected_eval_target if it's not set or not in the current eval_targets
            if st.session_state.selected_eval_target not in eval_targets:
                st.session_state.selected_eval_target = eval_targets[0]

            selected_target_index = eval_targets.index(st.session_state.selected_eval_target)

            st.session_state.selected_eval_target = st.selectbox(
                f"Selecciona el {st.session_state.eval_mode.split(' ')[1].lower()} a evaluar:",
                eval_targets,
                index=selected_target_index,
                key="selected_eval_target_box"
            )

            st.markdown(f"### Evaluaci√≥n para: **{st.session_state.selected_eval_target}**")

            # Display manual evaluation questions for the selected target
            st.subheader("Criterios de Evaluaci√≥n Manual:")
            for category, questions in rangos_detallados.items():
                if category == "Desempe√±o t√©cnico":
                    continue
                st.markdown(f"#### {category}")
                for question, options in questions.items():
                    unique_key = f"{category}_{question}_{st.session_state.selected_eval_target}"

                    sorted_options = sorted(options.items(), key=lambda item: item[0], reverse=True)
                    option_labels = [f"{v} ({k})" for k, v in sorted_options]
                    option_values = [k for k, v in sorted_options]

                    current_value = st.session_state.evaluations.get((category, question, st.session_state.selected_eval_target), None)

                    try:
                        # Set default to 0 if current_value is not found in option_values
                        default_index = option_values.index(current_value) if current_value in option_values else 0
                    except ValueError:
                        default_index = 0 # Fallback if value not in options (e.g., if options changed)

                    selected_option = st.radio(
                        question,
                        options=option_values,
                        format_func=lambda x: options[x],
                        index=default_index,
                        key=unique_key
                    )
                    st.session_state.evaluations[(category, question, st.session_state.selected_eval_target)] = selected_option

            st.markdown("---")

            # --- Display Consolidated Evaluation Matrix ---
            st.subheader("Matriz Consolidada de Evaluaciones")

            # Collect all distinct targets that have been evaluated
            all_evaluated_targets_manual = sorted(list(set([k[2] for k in st.session_state.evaluations.keys()])))

            # If the current evaluation mode is "Por Tipo de Servicio", filter targets to only those of type service, and vice versa for providers.
            # This ensures only relevant targets are shown in the matrix for the current mode.
            if st.session_state.eval_mode == "Por Tipo de Servicio":
                matrix_targets = [t for t in all_evaluated_targets_manual if t in st.session_state.df['tipo_de_servicio'].dropna().unique().tolist()]
                matrix_targets.sort()
            else: # Por Proveedor
                matrix_targets = [t for t in all_evaluated_targets_manual if t in st.session_state.df['proveedor'].dropna().unique().tolist()]
                matrix_targets.sort()

            # Prepare data for the matrix
            matrix_data = []
            categories_order = ["Calidad", "Oportunidad", "Precio", "Postventa"] # Define a fixed order for categories

            for category in categories_order:
                for question in rangos_detallados[category].keys():
                    row = {"Categor√≠a": category, "Pregunta": question}
                    for target in matrix_targets:
                        # Get the value for the specific target and question, default to None if not evaluated
                        value = st.session_state.evaluations.get((category, question, target), None)
                        row[target] = value
                    matrix_data.append(row)
            
            # Add technical performance metrics to the matrix
            # Ensure 'target_column_name_internal' is used for indexing the pre_calculated_metrics Series
            technical_metrics_row_data = {
                "Disponibilidad promedio (%)": st.session_state.pre_calculated_metrics.get('disponibilidad', pd.Series()).to_dict(),
                "MTTR promedio (hrs)": st.session_state.pre_calculated_metrics.get('mttr', pd.Series()).to_dict(),
                "MTBF promedio (hrs)": st.session_state.pre_calculated_metrics.get('mtbf', pd.Series()).to_dict(),
                "Rendimiento promedio equipos": st.session_state.pre_calculated_metrics.get('rendimiento', pd.Series()).to_dict(),
            }

            for metric_name, values_dict in technical_metrics_row_data.items():
                row = {"Categor√≠a": "Desempe√±o t√©cnico", "Pregunta": metric_name}
                for target in matrix_targets:
                    # Get the value for the specific target from the pre-calculated series
                    # Ensure the key for lookup matches the 'target_column_name_internal' used in the pre-calculation
                    value = values_dict.get(target, "N/A") # Default to "N/A" if not available
                    row[target] = value
                matrix_data.append(row)


            if matrix_data:
                evaluation_matrix_df = pd.DataFrame(matrix_data)
                
                # If there are no manual evaluations yet, the DataFrame might only contain technical metrics.
                # Check if there are any actual targets (columns other than 'Categor√≠a', 'Pregunta')
                data_columns = [col for col in evaluation_matrix_df.columns if col not in ["Categor√≠a", "Pregunta"]]

                if not data_columns:
                    st.info("A√∫n no se han registrado evaluaciones manuales para los objetivos seleccionados. La matriz mostrar√° solo m√©tricas t√©cnicas si est√°n disponibles.")
                else:
                    st.dataframe(evaluation_matrix_df)

                    # Calculate total scores and average scores
                    score_rows = []
                    for target in data_columns:
                        total_score = 0
                        num_questions = 0
                        
                        for category in categories_order:
                            for question in rangos_detallados[category].keys():
                                # Only count manual evaluation questions for the total score
                                if category != "Desempe√±o t√©cnico":
                                    score = st.session_state.evaluations.get((category, question, target))
                                    if score is not None:
                                        total_score += score
                                        num_questions += 1
                        
                        avg_score = total_score / num_questions if num_questions > 0 else 0
                        score_rows.append({"Categor√≠a": "Total Puntuaci√≥n", "Pregunta": "", target: total_score})
                        score_rows.append({"Categor√≠a": "Puntuaci√≥n Promedio", "Pregunta": "", target: f"{avg_score:.2f}"})

                    if score_rows:
                        score_df = pd.DataFrame(score_rows)
                        evaluation_matrix_df = pd.concat([evaluation_matrix_df, score_df], ignore_index=True)
                        st.dataframe(evaluation_matrix_df.set_index(["Categor√≠a", "Pregunta"]))
                    else:
                        st.info("No hay datos suficientes para calcular las puntuaciones totales o promedio.")

            else:
                st.info("No hay datos de evaluaci√≥n para mostrar. Por favor, realiza algunas evaluaciones manuales o verifica la carga de datos.")

elif st.session_state.page == "An√°lisis General":
    st.title("üìà An√°lisis General")
    st.markdown("""
        Explora visualizaciones y desgloses de datos clave como costos y cantidad de avisos por diferentes dimensiones.
    """)
    if st.session_state.df is None or st.session_state.df.empty:
        st.warning("Por favor, carga el archivo `BASE DE DATOS.XLSX` en la secci√≥n 'Inicio y Carga de Datos' para acceder a los an√°lisis.")
    else:
        analysis_app = AnalysisApp(st.session_state.df)
        analysis_app.display_analysis()
